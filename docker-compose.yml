version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: ecommerce_postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ecommerce_db}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/init-db:/docker-entrypoint-initdb.d
    networks:
      - ecommerce_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: ecommerce_redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    networks:
      - ecommerce_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ecommerce_backend
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      PORT: 3001
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-password}
      DB_NAME: ${POSTGRES_DB:-ecommerce_db}
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-this-in-production}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-7d}
      MAX_FILE_SIZE: ${MAX_FILE_SIZE:-5242880}
      UPLOAD_PATH: uploads
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost:3000}
      ORANGE_MONEY_API_KEY: ${ORANGE_MONEY_API_KEY:-}
      WAVE_API_KEY: ${WAVE_API_KEY:-}
      MOOV_API_KEY: ${MOOV_API_KEY:-}
      CARD_PAYMENT_API_KEY: ${CARD_PAYMENT_API_KEY:-}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:1b}
      AI_PROCESSING_ENABLED: ${AI_PROCESSING_ENABLED:-true}
      AI_FALLBACK_TO_RULES: ${AI_FALLBACK_TO_RULES:-true}
      AI_CONFIDENCE_THRESHOLD: ${AI_CONFIDENCE_THRESHOLD:-0.7}
    ports:
      - "${BACKEND_PORT:-3001}:3001"
    volumes:
      - backend_uploads:/app/uploads
    networks:
      - ecommerce_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/api/health", "||", "exit", "1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ecommerce_frontend
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3001/api}
      NEXT_PUBLIC_APP_URL: ${NEXT_PUBLIC_APP_URL:-http://localhost:3000}
    ports:
      - "${FRONTEND_PORT:-3002}:3000"
    networks:
      - ecommerce_network
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health.json"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    restart: unless-stopped

  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ecommerce_ollama
  #   ports:
  #     - "${OLLAMA_PORT:-11434}:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - ecommerce_network
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 60s
  #   restart: unless-stopped

  # ollama-init:
  #   image: ollama/ollama:latest
  #   container_name: ecommerce_ollama_init
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - ecommerce_network
  #   depends_on:
  #     ollama:
  #       condition: service_healthy
  #   command: >
  #     sh -c "
  #       echo 'Pulling Llama 3.2 1B model...' &&
  #       ollama pull llama3.2:1b &&
  #       echo 'Model pulled successfully!'
  #     "
  #   restart: "no"

volumes:
  postgres_data:
  redis_data:
  backend_uploads:
  # ollama_data:

networks:
  ecommerce_network:
    driver: bridge